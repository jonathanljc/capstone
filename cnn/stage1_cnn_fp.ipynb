{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: CNN + FP \u2014 LOS / NLOS Classification\n",
    "## 1D-CNN Baseline with FP_AMPL Late Fusion\n",
    "\n",
    "**Purpose**: 1D-CNN with FP_AMPL1/2/3 conditioning \u2014 fair comparison against LNN+FP.\n",
    "\n",
    "**FP Integration (Late Fusion)**: CIR passes through conv blocks \u2192 GAP \u2192 flatten. FP_AMPL1/2/3 passes through Linear(3\u219216). Both are concatenated and fed to the MLP classifier. This respects the CNN\u2019s inductive bias: local pattern extraction via convolution, with static features fused at the decision boundary.\n",
    "\n",
    "| | CNN+FP (this) | CNN (CIR only) | LNN+FP | LSTM+FP | BERT+FP |\n",
    "|---|---|---|---|---|---|\n",
    "| Input | CIR + FP_AMPL | CIR only | CIR + FP_AMPL | CIR + FP_AMPL | CIR + FP_AMPL |\n",
    "| FP usage | Late fusion (concat) | None | ODE h\u2080 init | LSTM h\u2080/c\u2080 init | Prefix token (self-attn) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"pre_crop\": 10,\n",
    "    \"post_crop\": 50,\n",
    "    \"total_len\": 60,\n",
    "    \"search_start\": 740,\n",
    "    \"search_end\": 890,\n",
    "    \"embedding_size\": 128,\n",
    "    \"input_channels\": 1,\n",
    "    \"fp_size\": 3,\n",
    "    \"fp_embed_size\": 16,\n",
    "    \"dropout\": 0.4,\n",
    "    \"batch_size\": 64,\n",
    "    \"max_epochs\": 40,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"warmup_epochs\": 3,\n",
    "    \"patience\": 10,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"val_ratio\": 0.15,\n",
    "    \"test_ratio\": 0.15,\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    classification_report, roc_curve, auc\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Data Loading, ROI Alignment & 70/15/15 Split\n",
    "\n",
    "Same CIR preprocessing as all other models. **Includes FP_AMPL1/2/3 extraction.**\n",
    "\n",
    "**Note**: CNN uses channels-first format `(B, 1, 60)` for Conv1d, while FP features are `(B, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_alignment(sig, search_start=CONFIG[\"search_start\"],\n",
    "                      search_end=CONFIG[\"search_end\"]):\n",
    "    region = sig[search_start:search_end]\n",
    "    if len(region) == 0:\n",
    "        return np.argmax(sig)\n",
    "    peak_local = np.argmax(region)\n",
    "    peak_idx = search_start + peak_local\n",
    "    peak_val = sig[peak_idx]\n",
    "    noise_section = sig[:search_start]\n",
    "    if len(noise_section) > 10:\n",
    "        noise_mean = np.mean(noise_section)\n",
    "        noise_std = np.std(noise_section)\n",
    "        threshold = max(noise_mean + 3 * noise_std, 0.05 * peak_val)\n",
    "    else:\n",
    "        threshold = 0.05 * peak_val\n",
    "    leading_edge = peak_idx\n",
    "    for i in range(peak_idx, max(search_start - 20, 0), -1):\n",
    "        if sig[i] < threshold:\n",
    "            leading_edge = i + 1\n",
    "            break\n",
    "    return leading_edge\n",
    "\n",
    "\n",
    "def load_cir_fp_dataset(filepath=\"../dataset/channels/combined_uwb_dataset.csv\"):\n",
    "    \"\"\"Returns: X (N, 1, 60) channels-first, y (N,), F (N, 3) \u2014 CIR + FP_AMPL.\"\"\"\n",
    "    PRE = CONFIG[\"pre_crop\"]\n",
    "    TOTAL = CONFIG[\"total_len\"]\n",
    "    processed_seqs, labels, fp_features = [], [], []\n",
    "\n",
    "    print(f\"Loading: {filepath}\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    cir_cols = sorted(\n",
    "        [c for c in df.columns if c.startswith('CIR')],\n",
    "        key=lambda x: int(x.replace('CIR', ''))\n",
    "    )\n",
    "    print(f\"  Samples: {len(df)}, CIR columns: {len(cir_cols)}\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sig = pd.to_numeric(row[cir_cols], errors='coerce').fillna(0).astype(float).values\n",
    "        rxpacc_col = 'RXPACC' if 'RXPACC' in row.index else 'RX_PACC'\n",
    "        rxpacc = float(row.get(rxpacc_col, 128.0))\n",
    "        if rxpacc > 0:\n",
    "            sig = sig / rxpacc\n",
    "\n",
    "        f1 = float(row.get('FP_AMPL1', 0)) / max(rxpacc, 1) / 64.0\n",
    "        f2 = float(row.get('FP_AMPL2', 0)) / max(rxpacc, 1) / 64.0\n",
    "        f3 = float(row.get('FP_AMPL3', 0)) / max(rxpacc, 1) / 64.0\n",
    "        fp_features.append([f1, f2, f3])\n",
    "\n",
    "        leading_edge = get_roi_alignment(sig)\n",
    "        start = max(0, leading_edge - PRE)\n",
    "        end = start + TOTAL\n",
    "        if end > len(sig):\n",
    "            end = len(sig)\n",
    "            start = max(0, end - TOTAL)\n",
    "        crop = sig[start:end]\n",
    "        if len(crop) < TOTAL:\n",
    "            crop = np.pad(crop, (0, TOTAL - len(crop)), mode='constant')\n",
    "        local_min, local_max = np.min(crop), np.max(crop)\n",
    "        rng = local_max - local_min\n",
    "        crop = (crop - local_min) / rng if rng > 0 else np.zeros(TOTAL)\n",
    "\n",
    "        processed_seqs.append(crop)\n",
    "        labels.append(float(row['Label']))\n",
    "\n",
    "    # CNN channels-first: (N, 1, 60)\n",
    "    X = np.array(processed_seqs).reshape(-1, 1, TOTAL).astype(np.float32)\n",
    "    y = np.array(labels).astype(np.float32)\n",
    "    F = np.array(fp_features).astype(np.float32)\n",
    "    print(f\"  Output shape: X={X.shape} (channels-first), y={y.shape}, F={F.shape}\")\n",
    "    print(f\"  LOS: {int(np.sum(y == 0))}, NLOS: {int(np.sum(y == 1))}\")\n",
    "    return X, y, F\n",
    "\n",
    "\n",
    "X_all, y_all, F_all = load_cir_fp_dataset(\"../dataset/channels/combined_uwb_dataset.csv\")\n",
    "\n",
    "indices = np.arange(len(y_all))\n",
    "idx_train, idx_temp = train_test_split(\n",
    "    indices, test_size=CONFIG[\"val_ratio\"] + CONFIG[\"test_ratio\"],\n",
    "    stratify=y_all, random_state=CONFIG[\"seed\"]\n",
    ")\n",
    "idx_val, idx_test = train_test_split(\n",
    "    idx_temp, test_size=CONFIG[\"test_ratio\"] / (CONFIG[\"val_ratio\"] + CONFIG[\"test_ratio\"]),\n",
    "    stratify=y_all[idx_temp], random_state=CONFIG[\"seed\"]\n",
    ")\n",
    "\n",
    "X_train, y_train, F_train = X_all[idx_train], y_all[idx_train], F_all[idx_train]\n",
    "X_val,   y_val,   F_val   = X_all[idx_val],   y_all[idx_val],   F_all[idx_val]\n",
    "X_test,  y_test,  F_test  = X_all[idx_test],  y_all[idx_test],  F_all[idx_test]\n",
    "\n",
    "print(f\"\\nSplit (70/15/15):\")\n",
    "print(f\"  Train: {X_train.shape[0]} (LOS: {int(np.sum(y_train==0))}, NLOS: {int(np.sum(y_train==1))})\")\n",
    "print(f\"  Val:   {X_val.shape[0]} (LOS: {int(np.sum(y_val==0))}, NLOS: {int(np.sum(y_val==1))})\")\n",
    "print(f\"  Test:  {X_test.shape[0]} (LOS: {int(np.sum(y_test==0))}, NLOS: {int(np.sum(y_test==1))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: CNN + FP Model Architecture (Late Fusion)\n",
    "\n",
    "Same 1D-CNN encoder as CIR-only CNN, with FP_AMPL1/2/3 fused at the classifier input.\n",
    "\n",
    "```\n",
    "CIR (1, 60) \u2192 Conv1d(1\u219216, k=5) \u2192 BN \u2192 ReLU\n",
    "            \u2192 Conv1d(16\u219232, k=5, s=2) \u2192 BN \u2192 ReLU   [60 \u2192 30]\n",
    "            \u2192 Conv1d(32\u2192128, k=3, s=2) \u2192 BN \u2192 ReLU  [30 \u2192 15]\n",
    "            \u2192 GAP \u2192 128-dim\n",
    "                                  \u2514\u2500\u2500 concat \u2500\u2500 144-dim \u2192 Classifier\n",
    "FP_AMPL (3) \u2192 Linear(3\u219216) \u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Why late fusion for CNN?** Convolutions are local pattern extractors \u2014 they scan the CIR for morphological features (peak shape, multipath spread). Static FP features don\u2019t have spatial locality, so they don\u2019t belong in the convolutional pathway. Instead, FP is projected to a dense representation and concatenated after pooling, right before the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_FP_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    1D-CNN with FP_AMPL late fusion.\n",
    "\n",
    "    CIR passes through 3 conv blocks with BatchNorm + GAP to produce a\n",
    "    128-dim embedding. FP_AMPL1/2/3 is projected to 16-dim via a linear\n",
    "    layer. Both are concatenated (144-dim) and fed to the MLP classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=1, embedding_size=128, dropout=0.4,\n",
    "                 fp_size=3, fp_embed_size=16):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.fp_embed_size = fp_embed_size\n",
    "\n",
    "        # 1D-CNN encoder (identical to CIR-only CNN)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(16), nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2, stride=2),\n",
    "            nn.BatchNorm1d(32), nn.ReLU(),\n",
    "            nn.Conv1d(32, embedding_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(embedding_size), nn.ReLU(),\n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # FP projection: (3,) -> (fp_embed_size,)\n",
    "        self.fp_proj = nn.Linear(fp_size, fp_embed_size)\n",
    "\n",
    "        # Classifier: (embedding_size + fp_embed_size) -> 1\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_size + fp_embed_size, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _encode_cir(self, x):\n",
    "        \"\"\"CNN encoder: (B, 1, 60) -> (B, embedding_size).\"\"\"\n",
    "        features = self.encoder(x)\n",
    "        return self.gap(features).squeeze(-1)\n",
    "\n",
    "    def forward(self, x, fp_features=None, return_dynamics=False):\n",
    "        # x: (batch, 1, 60) channels-first\n",
    "        cnn_embed = self._encode_cir(x)  # (B, 128)\n",
    "\n",
    "        if fp_features is not None:\n",
    "            fp_embed = self.fp_proj(fp_features)  # (B, 16)\n",
    "        else:\n",
    "            fp_embed = torch.zeros(x.size(0), self.fp_embed_size, device=x.device)\n",
    "\n",
    "        fused = torch.cat([cnn_embed, fp_embed], dim=-1)  # (B, 144)\n",
    "        pred = self.classifier(fused)\n",
    "\n",
    "        if return_dynamics:\n",
    "            # Return intermediate conv features for visualization\n",
    "            features = self.encoder(x)  # (B, 128, 15)\n",
    "            return pred, features\n",
    "        return pred\n",
    "\n",
    "    def embed(self, x, fp_features=None):\n",
    "        \"\"\"Return fused embedding for Stage 2/3 compatibility.\"\"\"\n",
    "        cnn_embed = self._encode_cir(x)\n",
    "        if fp_features is not None:\n",
    "            fp_embed = self.fp_proj(fp_features)\n",
    "            return torch.cat([cnn_embed, fp_embed], dim=-1)  # (B, 144)\n",
    "        return cnn_embed  # (B, 128)\n",
    "\n",
    "\n",
    "_m = CNN_FP_Classifier(\n",
    "    input_channels=CONFIG[\"input_channels\"],\n",
    "    embedding_size=CONFIG[\"embedding_size\"],\n",
    "    dropout=CONFIG[\"dropout\"],\n",
    "    fp_size=CONFIG[\"fp_size\"],\n",
    "    fp_embed_size=CONFIG[\"fp_embed_size\"],\n",
    ")\n",
    "_total = sum(p.numel() for p in _m.parameters())\n",
    "print(f\"CNN_FP_Classifier parameter count: {_total:,}\")\n",
    "print(f\"  Conv encoder:     {sum(p.numel() for p in _m.encoder.parameters()):,}\")\n",
    "print(f\"  FP projection:    {sum(p.numel() for p in _m.fp_proj.parameters()):,}\")\n",
    "print(f\"  Classifier:       {sum(p.numel() for p in _m.classifier.parameters()):,}\")\n",
    "print(f\"  CNN embed dim:    {_m.embedding_size}\")\n",
    "print(f\"  Fused dim:        {_m.embedding_size + _m.fp_embed_size}\")\n",
    "print(f\"\\n  FP conditioning: late fusion (concat after GAP)\")\n",
    "del _m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Training Pipeline\n",
    "\n",
    "Same training config as all other models: AdamW, cosine LR with warmup, early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_val, y_val, F_train, F_val, config=CONFIG):\n",
    "    print(f\"Training on {len(X_train)} samples, validating on {len(X_val)}\")\n",
    "    print(f\"  Input: CIR + FP_AMPL late fusion (F_train={F_train.shape})\")\n",
    "\n",
    "    X_tr = torch.tensor(X_train).to(device)\n",
    "    y_tr = torch.tensor(y_train).unsqueeze(1).to(device)\n",
    "    X_va = torch.tensor(X_val).to(device)\n",
    "    y_va = torch.tensor(y_val).unsqueeze(1).to(device)\n",
    "    F_tr = torch.tensor(F_train).to(device)\n",
    "    F_va = torch.tensor(F_val).to(device)\n",
    "\n",
    "    train_ds = TensorDataset(X_tr, y_tr, F_tr)\n",
    "    train_loader = DataLoader(train_ds, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    model = CNN_FP_Classifier(\n",
    "        input_channels=config[\"input_channels\"],\n",
    "        embedding_size=config[\"embedding_size\"],\n",
    "        dropout=config[\"dropout\"],\n",
    "        fp_size=config[\"fp_size\"],\n",
    "        fp_embed_size=config[\"fp_embed_size\"],\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"],\n",
    "                            weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    warmup_epochs = config[\"warmup_epochs\"]\n",
    "    total_epochs  = config[\"max_epochs\"]\n",
    "\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            return (epoch + 1) / warmup_epochs\n",
    "        progress = (epoch - warmup_epochs) / max(1, total_epochs - warmup_epochs)\n",
    "        return max(0.01, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
    "\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": [], \"lr\": []}\n",
    "    best_val_acc = 0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(config[\"max_epochs\"]):\n",
    "        model.train()\n",
    "        train_loss_sum = 0\n",
    "        train_correct, train_total = 0, 0\n",
    "\n",
    "        for batch_x, batch_y, batch_f in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch_x, fp_features=batch_f)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), config[\"grad_clip\"])\n",
    "            optimizer.step()\n",
    "            train_loss_sum += loss.item() * len(batch_x)\n",
    "            train_correct  += ((pred > 0.5).float() == batch_y).sum().item()\n",
    "            train_total    += len(batch_x)\n",
    "\n",
    "        train_loss = train_loss_sum / train_total\n",
    "        train_acc  = train_correct / train_total\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_va, fp_features=F_va)\n",
    "            val_loss = criterion(val_pred, y_va)\n",
    "            val_acc  = ((val_pred > 0.5).float() == y_va).float().mean().item()\n",
    "\n",
    "        lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss.item())\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"lr\"].append(lr_now)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if epoch % 5 == 0 or epoch == config[\"max_epochs\"] - 1:\n",
    "            print(f\"  Ep {epoch:>3} | Loss: {train_loss:.4f} | Val Acc: {100*val_acc:.2f}% | Best: {100*best_val_acc:.2f}% | LR: {lr_now:.1e}\")\n",
    "\n",
    "        if patience_counter >= config[\"patience\"]:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"\\nBest Validation Accuracy: {100*best_val_acc:.2f}%\")\n",
    "    return model, (X_va, y_va, F_va), history\n",
    "\n",
    "\n",
    "best_model, best_data, best_history = train_model(X_train, y_train, X_val, y_val, F_train, F_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diagnostics(model, val_data, history):\n",
    "    X_va, y_va, F_va = val_data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds, conv_features = model(X_va, fp_features=F_va, return_dynamics=True)\n",
    "        embeddings = model.embed(X_va, fp_features=F_va).cpu().numpy()\n",
    "\n",
    "    y_true = y_va.cpu().numpy().flatten()\n",
    "    y_prob = preds.cpu().numpy().flatten()\n",
    "    y_pred = (y_prob > 0.5).astype(float)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(24, 14))\n",
    "    plt.subplots_adjust(hspace=0.35, wspace=0.3)\n",
    "\n",
    "    ax = axs[0, 0]\n",
    "    ax.plot(history[\"train_loss\"], label=\"Train Loss\", color=\"#3498db\", lw=2)\n",
    "    ax.plot(history[\"val_loss\"],   label=\"Val Loss\",   color=\"#e74c3c\", lw=2, ls=\"--\")\n",
    "    ax.set_title(\"Learning Curves\"); ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"Loss (BCE)\")\n",
    "    ax.legend(fontsize=9); ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax = axs[0, 1]\n",
    "    ax.plot(history[\"train_acc\"], label=\"Train Acc\", color=\"#3498db\", lw=2)\n",
    "    ax.plot(history[\"val_acc\"],   label=\"Val Acc\",   color=\"#e74c3c\", lw=2, ls=\"--\")\n",
    "    ax.set_title(\"Accuracy Curves\"); ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_ylim([0.4, 1.05]); ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax = axs[0, 2]\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"LOS\", \"NLOS\"])\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    ax.set_title(f\"Confusion Matrix (Acc: {100*acc:.1f}%)\")\n",
    "\n",
    "    ax = axs[1, 0]\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, color=\"#e74c3c\", lw=2, label=f\"AUC = {roc_auc:.4f}\")\n",
    "    ax.plot([0, 1], [0, 1], \"k--\", lw=1, alpha=0.5)\n",
    "    ax.set_title(\"ROC Curve\"); ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\")\n",
    "    ax.legend(loc=\"lower right\"); ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # PCA on fused embedding (CNN + FP)\n",
    "    ax = axs[1, 1]\n",
    "    scaler = StandardScaler()\n",
    "    emb_scaled = scaler.fit_transform(embeddings)\n",
    "    pca = PCA(n_components=2)\n",
    "    emb_pca = pca.fit_transform(emb_scaled)\n",
    "    los_mask  = y_true == 0\n",
    "    nlos_mask = y_true == 1\n",
    "    ax.scatter(emb_pca[nlos_mask, 0], emb_pca[nlos_mask, 1],\n",
    "               c=\"#e74c3c\", s=25, alpha=0.6, edgecolors=\"darkred\", linewidths=0.3, label=\"NLOS\", zorder=4)\n",
    "    ax.scatter(emb_pca[los_mask, 0], emb_pca[los_mask, 1],\n",
    "               c=\"#2ecc71\", s=25, alpha=0.6, edgecolors=\"darkgreen\", linewidths=0.3, label=\"LOS\", zorder=5)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.set_title(f\"Fused Embedding (PCA on {embeddings.shape[1]}-dim, n={len(y_true)})\")\n",
    "    ax.set_xlabel(f\"PC1 ({100*pca.explained_variance_ratio_[0]:.1f}%)\")\n",
    "    ax.set_ylabel(f\"PC2 ({100*pca.explained_variance_ratio_[1]:.1f}%)\")\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "    ax = axs[1, 2]\n",
    "    ax.hist(y_prob[y_true == 0], bins=30, alpha=0.6, color=\"#27ae60\", label=\"LOS samples\", density=True)\n",
    "    ax.hist(y_prob[y_true == 1], bins=30, alpha=0.6, color=\"#e74c3c\", label=\"NLOS samples\", density=True)\n",
    "    ax.axvline(0.5, color=\"black\", ls=\"--\", lw=1.5, label=\"Threshold\")\n",
    "    ax.set_title(\"Prediction Distribution\"); ax.set_xlabel(\"P(NLOS)\"); ax.set_ylabel(\"Density\")\n",
    "    ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(\"CNN+FP \u2014 Stage 1 Diagnostics (CIR + FP_AMPL late fusion)\",\n",
    "                 fontsize=16, fontweight=\"bold\", y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_diagnostics(best_model, best_data, best_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: CNN Feature Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_maps(model, val_data, n_samples=5):\n",
    "    X_va, y_va, F_va = val_data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, conv_features = model(X_va, fp_features=F_va, return_dynamics=True)\n",
    "\n",
    "    y_true = y_va.cpu().numpy().flatten()\n",
    "    # conv_features: (batch, 128, 15) \u2014 last conv layer output\n",
    "    feat_norm = torch.norm(conv_features, dim=1).cpu().numpy()  # (batch, 15)\n",
    "    x_input = X_va.cpu().numpy().squeeze(1)  # (batch, 60)\n",
    "\n",
    "    los_idx  = np.where(y_true == 0)[0][:n_samples]\n",
    "    nlos_idx = np.where(y_true == 1)[0][:n_samples]\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "    titles = [\n",
    "        (\"LOS signal\", los_idx, \"#2ecc71\", x_input),\n",
    "        (\"LOS ||features|| (CNN+FP)\", los_idx, \"#27ae60\", feat_norm),\n",
    "        (\"NLOS signal\", nlos_idx, \"#e74c3c\", x_input),\n",
    "        (\"NLOS ||features|| (CNN+FP)\", nlos_idx, \"#c0392b\", feat_norm),\n",
    "    ]\n",
    "    for ax, (title, idx, color, data) in zip(axs.flat, titles):\n",
    "        for i in idx:\n",
    "            ax.plot(data[i], alpha=0.55, color=color, lw=1.3)\n",
    "        ax.set_title(title, fontsize=10, fontweight=\"bold\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if \"signal\" in title:\n",
    "            ax.set_xlabel(\"CIR sample index\")\n",
    "            ax.set_ylabel(\"Normalised CIR\")\n",
    "        else:\n",
    "            ax.set_xlabel(\"Conv output position (downsampled)\")\n",
    "            ax.set_ylabel(\"Feature Norm\")\n",
    "    plt.suptitle(\"CNN+FP Feature Map Profile \u2014 Late Fusion\",\n",
    "                 fontsize=13, fontweight=\"bold\", y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_feature_maps(best_model, best_data, n_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Test Set Evaluation & Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "X_te = torch.tensor(X_test).to(device)\n",
    "y_te = torch.tensor(y_test).unsqueeze(1).to(device)\n",
    "F_te = torch.tensor(F_test).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_pred = best_model(X_te, fp_features=F_te)\n",
    "    test_prob = test_pred.cpu().numpy().flatten()\n",
    "    test_acc  = ((test_pred > 0.5).float() == y_te).float().mean().item()\n",
    "    test_pred_np = (test_prob > 0.5).astype(float)\n",
    "    test_true_np = y_test.flatten()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_true_np, test_prob)\n",
    "test_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"Test Accuracy: {100*test_acc:.2f}%\")\n",
    "print(f\"Test AUC:      {test_auc:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(test_true_np, test_pred_np, target_names=[\"LOS\", \"NLOS\"]))\n",
    "\n",
    "cm = confusion_matrix(test_true_np, test_pred_np)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"LOS\", \"NLOS\"])\n",
    "disp.plot(ax=axs[0], cmap=\"Blues\", colorbar=False)\n",
    "axs[0].set_title(f\"CNN+FP \u2014 Test (Acc: {100*test_acc:.1f}%)\")\n",
    "axs[1].plot(fpr, tpr, color=\"#e74c3c\", lw=2, label=f\"AUC = {test_auc:.4f}\")\n",
    "axs[1].plot([0, 1], [0, 1], \"k--\", lw=1, alpha=0.5)\n",
    "axs[1].set_title(\"CNN+FP \u2014 Test ROC\"); axs[1].set_xlabel(\"FPR\"); axs[1].set_ylabel(\"TPR\")\n",
    "axs[1].legend(loc=\"lower right\"); axs[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nModel: CNN_FP_Classifier | Fused dim: {best_model.embedding_size + best_model.fp_embed_size} | Params: {sum(p.numel() for p in best_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), \"stage1_cnn_fp_best.pt\")\n",
    "print(\"Saved: stage1_cnn_fp_best.pt\")\n",
    "torch.save({\"config\": CONFIG}, \"stage1_cnn_fp_config.pt\")\n",
    "print(\"Saved: stage1_cnn_fp_config.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stage 1 CNN+FP complete.\")\n",
    "print(\"Compare with: CNN (CIR only), LNN+FP, LSTM+FP, BERT+FP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}