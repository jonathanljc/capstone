{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Unseen Dataset Evaluation\n",
    "## CNN + FP (1D-CNN + FP_AMPL Late Fusion) — LOS/NLOS Classification\n",
    "\n",
    "Evaluates trained `stage1_cnn_fp_best.pt` on **completely unseen** 4 scenarios (2400 samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"pre_crop\": 10,\n",
    "    \"post_crop\": 50,\n",
    "    \"total_len\": 60,\n",
    "    \"search_start\": 740,\n",
    "    \"search_end\": 890,\n",
    "    \"embedding_size\": 128,\n",
    "    \"input_channels\": 1,\n",
    "    \"fp_size\": 3,\n",
    "    \"fp_embed_size\": 16,\n",
    "    \"dropout\": 0.4,\n",
    "    \"batch_size\": 64,\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    classification_report, roc_curve, auc\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 · Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_FP_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    1D-CNN with FP_AMPL late fusion.\n",
    "\n",
    "    CIR passes through 3 conv blocks with BatchNorm + GAP to produce a\n",
    "    128-dim embedding. FP_AMPL1/2/3 is projected to 16-dim via a linear\n",
    "    layer. Both are concatenated (144-dim) and fed to the MLP classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=1, embedding_size=128, dropout=0.4,\n",
    "                 fp_size=3, fp_embed_size=16):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.fp_embed_size = fp_embed_size\n",
    "\n",
    "        # 1D-CNN encoder (identical to CIR-only CNN)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(16), nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2, stride=2),\n",
    "            nn.BatchNorm1d(32), nn.ReLU(),\n",
    "            nn.Conv1d(32, embedding_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(embedding_size), nn.ReLU(),\n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # FP projection: (3,) -> (fp_embed_size,)\n",
    "        self.fp_proj = nn.Linear(fp_size, fp_embed_size)\n",
    "\n",
    "        # Classifier: (embedding_size + fp_embed_size) -> 1\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_size + fp_embed_size, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _encode_cir(self, x):\n",
    "        \"\"\"CNN encoder: (B, 1, 60) -> (B, embedding_size).\"\"\"\n",
    "        features = self.encoder(x)\n",
    "        return self.gap(features).squeeze(-1)\n",
    "\n",
    "    def forward(self, x, fp_features=None, return_dynamics=False):\n",
    "        cnn_embed = self._encode_cir(x)  # (B, 128)\n",
    "\n",
    "        if fp_features is not None:\n",
    "            fp_embed = self.fp_proj(fp_features)  # (B, 16)\n",
    "        else:\n",
    "            fp_embed = torch.zeros(x.size(0), self.fp_embed_size, device=x.device)\n",
    "\n",
    "        fused = torch.cat([cnn_embed, fp_embed], dim=-1)  # (B, 144)\n",
    "        pred = self.classifier(fused)\n",
    "\n",
    "        if return_dynamics:\n",
    "            features = self.encoder(x)  # (B, 128, 15)\n",
    "            return pred, features\n",
    "        return pred\n",
    "\n",
    "    def embed(self, x, fp_features=None):\n",
    "        \"\"\"Return fused embedding for Stage 2/3 compatibility.\"\"\"\n",
    "        cnn_embed = self._encode_cir(x)\n",
    "        if fp_features is not None:\n",
    "            fp_embed = self.fp_proj(fp_features)\n",
    "            return torch.cat([cnn_embed, fp_embed], dim=-1)  # (B, 144)\n",
    "        return cnn_embed  # (B, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 · Load Unseen Dataset\n",
    "\n",
    "Same preprocessing as training. **Includes FP_AMPL1/2/3 extraction.**\n",
    "\n",
    "**Note**: CNN uses channels-first format `(B, 1, 60)` for Conv1d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_alignment(sig, search_start=CONFIG[\"search_start\"],\n",
    "                      search_end=CONFIG[\"search_end\"]):\n",
    "    region = sig[search_start:search_end]\n",
    "    if len(region) == 0:\n",
    "        return np.argmax(sig)\n",
    "    peak_local = np.argmax(region)\n",
    "    peak_idx = search_start + peak_local\n",
    "    peak_val = sig[peak_idx]\n",
    "    noise_section = sig[:search_start]\n",
    "    if len(noise_section) > 10:\n",
    "        noise_mean = np.mean(noise_section)\n",
    "        noise_std = np.std(noise_section)\n",
    "        threshold = max(noise_mean + 3 * noise_std, 0.05 * peak_val)\n",
    "    else:\n",
    "        threshold = 0.05 * peak_val\n",
    "    leading_edge = peak_idx\n",
    "    for i in range(peak_idx, max(search_start - 20, 0), -1):\n",
    "        if sig[i] < threshold:\n",
    "            leading_edge = i + 1\n",
    "            break\n",
    "    return leading_edge\n",
    "\n",
    "\n",
    "def load_unseen_fp_dataset(filepath):\n",
    "    \"\"\"Load and preprocess the unseen dataset — CIR (channels-first) + FP_AMPL features.\"\"\"\n",
    "    PRE = CONFIG[\"pre_crop\"]\n",
    "    TOTAL = CONFIG[\"total_len\"]\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Loaded {len(df)} rows from {filepath}\")\n",
    "\n",
    "    cir_cols = sorted(\n",
    "        [c for c in df.columns if c.startswith(\"CIR\")],\n",
    "        key=lambda c: int(c.replace(\"CIR\", \"\"))\n",
    "    )\n",
    "\n",
    "    X_list, y_list, fp_list = [], [], []\n",
    "    source_files = []\n",
    "    skipped = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sig = pd.to_numeric(row[cir_cols], errors='coerce').fillna(0).astype(float).values\n",
    "        rxpacc_col = 'RXPACC' if 'RXPACC' in row.index else 'RX_PACC'\n",
    "        rxpacc = float(row.get(rxpacc_col, 128.0))\n",
    "        if rxpacc <= 0:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        sig = sig / rxpacc\n",
    "\n",
    "        f1 = float(row.get('FP_AMPL1', 0)) / max(rxpacc, 1) / 64.0\n",
    "        f2 = float(row.get('FP_AMPL2', 0)) / max(rxpacc, 1) / 64.0\n",
    "        f3 = float(row.get('FP_AMPL3', 0)) / max(rxpacc, 1) / 64.0\n",
    "        fp_list.append([f1, f2, f3])\n",
    "\n",
    "        leading_edge = get_roi_alignment(sig)\n",
    "        start = max(0, leading_edge - PRE)\n",
    "        end = start + TOTAL\n",
    "        if end > len(sig):\n",
    "            end = len(sig)\n",
    "            start = max(0, end - TOTAL)\n",
    "        crop = sig[start:end]\n",
    "        if len(crop) < TOTAL:\n",
    "            crop = np.pad(crop, (0, TOTAL - len(crop)), mode='constant')\n",
    "        local_min = np.min(crop)\n",
    "        local_max = np.max(crop)\n",
    "        rng = local_max - local_min\n",
    "        if rng > 0:\n",
    "            crop = (crop - local_min) / rng\n",
    "        else:\n",
    "            crop = np.zeros(TOTAL)\n",
    "\n",
    "        X_list.append(crop)\n",
    "        y_list.append(float(row[\"Label\"]))\n",
    "        source_files.append(row[\"Source_File\"])\n",
    "\n",
    "    if skipped:\n",
    "        print(f\"Skipped {skipped} rows (bad RXPACC)\")\n",
    "\n",
    "    # CNN channels-first: (N, 1, 60)\n",
    "    X = np.array(X_list, dtype=np.float32).reshape(-1, 1, TOTAL)\n",
    "    y = np.array(y_list, dtype=np.float32)\n",
    "    F = np.array(fp_list, dtype=np.float32)\n",
    "\n",
    "    print(f\"Preprocessed: {len(y)} samples  |  LOS: {int((y==0).sum())}  |  NLOS: {int((y==1).sum())}\")\n",
    "    print(f\"X shape: {X.shape} (channels-first)  |  F shape: {F.shape}\")\n",
    "    return X, y, F, source_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unseen, y_unseen, F_unseen, sources = load_unseen_fp_dataset(\n",
    "    \"../dataset/channels/unseen_dataset.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 · Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_FP_Classifier(\n",
    "    input_channels=CONFIG[\"input_channels\"],\n",
    "    embedding_size=CONFIG[\"embedding_size\"],\n",
    "    dropout=CONFIG[\"dropout\"],\n",
    "    fp_size=CONFIG[\"fp_size\"],\n",
    "    fp_embed_size=CONFIG[\"fp_embed_size\"],\n",
    ").to(device)\n",
    "\n",
    "state_dict = torch.load(\"stage1_cnn_fp_best.pt\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "print(f\"Model loaded: {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 · Inference on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = torch.tensor(X_unseen).to(device)\n",
    "y_te = torch.tensor(y_unseen).unsqueeze(1).to(device)\n",
    "F_te = torch.tensor(F_unseen).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(X_te, fp_features=F_te)\n",
    "    pred_binary = (pred > 0.5).float()\n",
    "    accuracy = (pred_binary == y_te).float().mean().item()\n",
    "\n",
    "pred_np = pred.cpu().numpy().flatten()\n",
    "pred_label_np = (pred_np > 0.5).astype(float)\n",
    "true_np = y_unseen.flatten()\n",
    "\n",
    "print(f\"Unseen Dataset Accuracy: {100 * accuracy:.2f}%\")\n",
    "print(f\"{'='*50}\")\n",
    "print(classification_report(true_np, pred_label_np, target_names=[\"LOS\", \"NLOS\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 · Per-Scenario Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_arr = np.array(sources)\n",
    "scenario_names = np.array([\"_\".join(s.split(\"_\")[:2]) for s in sources_arr])\n",
    "unique_scenarios = sorted(set(scenario_names))\n",
    "\n",
    "print(f\"{'Scenario':<16} {'Type':<6} {'Samples':>7} {'Correct':>8} {'Accuracy':>9}\")\n",
    "print(\"-\" * 52)\n",
    "\n",
    "for scenario in unique_scenarios:\n",
    "    mask = scenario_names == scenario\n",
    "    s_true = true_np[mask]\n",
    "    s_pred = pred_label_np[mask]\n",
    "    s_correct = (s_true == s_pred).sum()\n",
    "    s_total = len(s_true)\n",
    "    s_acc = s_correct / s_total * 100\n",
    "    s_type = \"NLOS\" if \"nlos\" in scenario else \"LOS\"\n",
    "    print(f\"{scenario:<16} {s_type:<6} {s_total:>7} {s_correct:>8} {s_acc:>8.2f}%\")\n",
    "\n",
    "print(\"-\" * 52)\n",
    "print(f\"{'TOTAL':<16} {'':6} {len(true_np):>7} {int((true_np == pred_label_np).sum()):>8} {100*accuracy:>8.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 · Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "cm = confusion_matrix(true_np, pred_label_np)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"LOS\", \"NLOS\"])\n",
    "disp.plot(ax=axes[0], cmap=\"Blues\", values_format=\"d\")\n",
    "axes[0].set_title(f\"Overall — Unseen Dataset\\nAccuracy: {100*accuracy:.2f}%\")\n",
    "\n",
    "scenario_labels, scenario_accs, scenario_colors = [], [], []\n",
    "for scenario in unique_scenarios:\n",
    "    mask = scenario_names == scenario\n",
    "    s_acc = (true_np[mask] == pred_label_np[mask]).mean() * 100\n",
    "    scenario_labels.append(scenario)\n",
    "    scenario_accs.append(s_acc)\n",
    "    scenario_colors.append(\"#2ecc71\" if \"los\" in scenario and \"nlos\" not in scenario else \"#e74c3c\")\n",
    "\n",
    "bars = axes[1].barh(scenario_labels, scenario_accs, color=scenario_colors, edgecolor=\"white\", height=0.6)\n",
    "axes[1].set_xlim(0, 105)\n",
    "axes[1].set_xlabel(\"Accuracy (%)\")\n",
    "axes[1].set_title(\"Per-Scenario Accuracy\")\n",
    "for bar, acc in zip(bars, scenario_accs):\n",
    "    axes[1].text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "                 f\"{acc:.1f}%\", va=\"center\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 · ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(true_np, pred_np)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.plot(fpr, tpr, color=\"#3498db\", lw=2, label=f\"Unseen AUC = {roc_auc:.4f}\")\n",
    "ax.plot([0, 1], [0, 1], \"k--\", lw=1, alpha=0.5)\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(\"ROC Curve — Unseen Dataset (CNN+FP)\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 · Embedding Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los_mask = true_np == 0\n",
    "nlos_mask = true_np == 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model.embed(X_te, fp_features=F_te).cpu().numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "emb_scaled = scaler.fit_transform(embeddings)\n",
    "pca = PCA(n_components=2)\n",
    "emb_2d = pca.fit_transform(emb_scaled)\n",
    "\n",
    "misclassified = true_np != pred_label_np\n",
    "los_correct = los_mask & ~misclassified\n",
    "los_wrong = los_mask & misclassified\n",
    "nlos_correct = nlos_mask & ~misclassified\n",
    "nlos_wrong = nlos_mask & misclassified\n",
    "\n",
    "tn = int(los_correct.sum())\n",
    "fp = int(los_wrong.sum())\n",
    "tp = int(nlos_correct.sum())\n",
    "fn = int(nlos_wrong.sum())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "cm = confusion_matrix(true_np, pred_label_np)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"LOS\", \"NLOS\"])\n",
    "disp.plot(ax=axes[0], cmap=\"Blues\", values_format=\"d\")\n",
    "axes[0].set_title(f\"Confusion Matrix\\nAccuracy: {100*accuracy:.2f}%\", fontsize=13)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.scatter(emb_2d[los_correct, 0], emb_2d[los_correct, 1],\n",
    "           c=\"#2ecc71\", alpha=0.4, s=15, label=f\"TN — LOS correct ({tn})\", zorder=3)\n",
    "ax.scatter(emb_2d[nlos_correct, 0], emb_2d[nlos_correct, 1],\n",
    "           c=\"#e74c3c\", alpha=0.4, s=15, label=f\"TP — NLOS correct ({tp})\", zorder=3)\n",
    "if fp > 0:\n",
    "    ax.scatter(emb_2d[los_wrong, 0], emb_2d[los_wrong, 1],\n",
    "               c=\"gold\", marker='X', s=60, edgecolors='black', linewidths=0.8,\n",
    "               alpha=0.9, label=f\"FP — LOS\\u2192NLOS ({fp})\", zorder=7)\n",
    "if fn > 0:\n",
    "    ax.scatter(emb_2d[nlos_wrong, 0], emb_2d[nlos_wrong, 1],\n",
    "               c=\"darkorange\", marker='X', s=60, edgecolors='black', linewidths=0.8,\n",
    "               alpha=0.9, label=f\"FN — NLOS\\u2192LOS ({fn})\", zorder=7)\n",
    "\n",
    "ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "ax.set_title(\"CNN+FP Embedding (PCA)\", fontsize=13)\n",
    "ax.legend(loc=\"upper left\", fontsize=9, title=\"Confusion Matrix\", title_fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"TN: {tn} | FP: {fp} | TP: {tp} | FN: {fn} | Total: {tn+fp+tp+fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 · Prediction Confidence Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "ax.hist(pred_np[true_np == 0], bins=40, alpha=0.6, color=\"#27ae60\",\n",
    "        label=\"LOS samples\", density=True)\n",
    "ax.hist(pred_np[true_np == 1], bins=40, alpha=0.6, color=\"#e74c3c\",\n",
    "        label=\"NLOS samples\", density=True)\n",
    "ax.axvline(0.5, color=\"black\", ls=\"--\", lw=1.5, label=\"Threshold\")\n",
    "ax.set_xlabel(\"P(NLOS)\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(\"Prediction Confidence Distribution — Unseen Dataset (CNN+FP)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 · Misclassified Samples Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = true_np != pred_label_np\n",
    "n_wrong = misclassified.sum()\n",
    "\n",
    "if n_wrong == 0:\n",
    "    print(\"No misclassified samples — perfect accuracy on unseen data!\")\n",
    "else:\n",
    "    print(f\"Misclassified: {n_wrong} / {len(true_np)} ({100*n_wrong/len(true_np):.2f}%)\")\n",
    "    print(f\"\\n{'Source File':<28} {'True':>6} {'Pred':>6} {'P(NLOS)':>9}\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    mis_idx = np.where(misclassified)[0]\n",
    "    for i in mis_idx[:30]:\n",
    "        lbl = \"NLOS\" if true_np[i] == 1 else \"LOS\"\n",
    "        plb = \"NLOS\" if pred_label_np[i] == 1 else \"LOS\"\n",
    "        print(f\"{sources[i]:<28} {lbl:>6} {plb:>6} {pred_np[i]:>9.4f}\")\n",
    "\n",
    "    if len(mis_idx) > 30:\n",
    "        print(f\"... and {len(mis_idx) - 30} more\")\n",
    "\n",
    "    print(f\"\\n{'Scenario':<16} {'Errors':>7} {'Total':>7} {'Error Rate':>11}\")\n",
    "    print(\"-\" * 45)\n",
    "    for scenario in unique_scenarios:\n",
    "        mask = scenario_names == scenario\n",
    "        errs = (true_np[mask] != pred_label_np[mask]).sum()\n",
    "        total = mask.sum()\n",
    "        if errs > 0:\n",
    "            print(f\"{scenario:<16} {errs:>7} {total:>7} {100*errs/total:>10.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unseen dataset evaluation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}