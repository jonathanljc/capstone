{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Physics-Informed Hybrid Liquid Neural Network (PI-HLNN)\n",
    "## LOS / NLOS Classification from Raw CIR\n",
    "\n",
    "**Architecture**: Pure Liquid Neural Network with input+state driven time constants (tau).\n",
    "**Physics-Informed**: RXPACC normalization, ODE dynamics, tau via `softplus` (no hardcoded targets).\n",
    "**Hybrid**: Combines physics priors (preprocessing, loss, ODE structure) with data-driven learned dynamics.\n",
    "**Input**: Raw 60-sample CIR window â€” no hand-crafted features. The LNN learns temporal dynamics directly from the signal.\n",
    "**Training**: `combined_uwb_dataset.csv` (3600 samples, 6 UWB channels), 70/15/15 train/val/test split.\n",
    "**Pipeline**: **Stage 1 (LNN â†’ LOS/NLOS)** â†’ Stage 2 (MLP â†’ single/multi bounce) â†’ Stage 3 (MLP â†’ ranging error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CONFIG = {\n    \"pre_crop\": 10,\n    \"post_crop\": 50,\n    \"total_len\": 60,\n    \"search_start\": 740,\n    \"search_end\": 890,\n    \"hidden_size\": 64,\n    \"input_size\": 1,\n    \"dropout\": 0.2,\n    \"ode_unfolds\": 6,\n    \"batch_size\": 64,\n    \"max_epochs\": 40,\n    \"lr\": 1e-3,\n    \"weight_decay\": 1e-4,\n    \"warmup_epochs\": 3,\n    \"patience\": 10,\n    \"grad_clip\": 1.0,\n    \"val_ratio\": 0.15,\n    \"test_ratio\": 0.15,\n    \"seed\": 42,\n}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Data Loading, ROI Alignment & 70/15/15 Split\n",
    "\n",
    "**ROI search range**: `[740, 890]` â€” derived from empirical CIR peak analysis:\n",
    "- All CIR peaks across 36 CSV files (LOS + NLOS, 6 channels) fall within indices **743â€“807**.\n",
    "- `search_start=740`: 3 indices before the earliest observed peak (743), provides margin.\n",
    "- `search_end=890`: ~80 indices past the latest observed peak (807), captures any multipath tail.\n",
    "- Noise floor estimated from indices 0â€“739 (740 samples of pure noise = robust estimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ../dataset/channels/combined_uwb_dataset.csv\n",
      "  Samples: 3600, CIR columns: 1016\n",
      "  Output shape: X=(3600, 60, 1), y=(3600,)\n",
      "  LOS: 1800, NLOS: 1800\n",
      "\n",
      "Split (70/15/15):\n",
      "  Train: 2520 (LOS: 1260, NLOS: 1260)\n",
      "  Val:   540 (LOS: 270, NLOS: 270)\n",
      "  Test:  540 (LOS: 270, NLOS: 270)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# SMART ROI ALIGNMENT\n",
    "# ==========================================\n",
    "def get_roi_alignment(sig, search_start=CONFIG[\"search_start\"],\n",
    "                      search_end=CONFIG[\"search_end\"]):\n",
    "    \"\"\"\n",
    "    Find the leading edge of the pulse by backtracking from peak.\n",
    "    Uses noise floor estimation (mean + 3*std) or 5% of peak.\n",
    "\n",
    "    Search range [740, 890] derived from empirical CIR peak analysis:\n",
    "      - All peaks across 36 files fall within indices 743-807\n",
    "      - 740 start = margin before earliest peak\n",
    "      - 890 end = margin past latest multipath outlier\n",
    "    \"\"\"\n",
    "    region = sig[search_start:search_end]\n",
    "    if len(region) == 0:\n",
    "        return np.argmax(sig)\n",
    "\n",
    "    peak_local = np.argmax(region)\n",
    "    peak_idx = search_start + peak_local\n",
    "    peak_val = sig[peak_idx]\n",
    "\n",
    "    # Noise floor from samples before the search region\n",
    "    noise_section = sig[:search_start]\n",
    "    if len(noise_section) > 10:\n",
    "        noise_mean = np.mean(noise_section)\n",
    "        noise_std = np.std(noise_section)\n",
    "        threshold = max(noise_mean + 3 * noise_std, 0.05 * peak_val)\n",
    "    else:\n",
    "        threshold = 0.05 * peak_val\n",
    "\n",
    "    # Backtrack from peak to find leading edge\n",
    "    leading_edge = peak_idx\n",
    "    for i in range(peak_idx, max(search_start - 20, 0), -1):\n",
    "        if sig[i] < threshold:\n",
    "            leading_edge = i + 1\n",
    "            break\n",
    "\n",
    "    return leading_edge\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DATASET LOADER (CIR-ONLY)\n",
    "# ==========================================\n",
    "def load_cir_dataset(filepath=\"../dataset/channels/combined_uwb_dataset.csv\"):\n",
    "    \"\"\"\n",
    "    Load and preprocess CIR data. Returns only the CIR sequence and labels.\n",
    "    No hand-crafted features â€” the LNN learns directly from the signal.\n",
    "    \"\"\"\n",
    "    PRE = CONFIG[\"pre_crop\"]\n",
    "    POST = CONFIG[\"post_crop\"]\n",
    "    TOTAL = CONFIG[\"total_len\"]\n",
    "\n",
    "    processed_seqs = []\n",
    "    labels = []\n",
    "\n",
    "    print(f\"Loading: {filepath}\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    cir_cols = sorted(\n",
    "        [c for c in df.columns if c.startswith('CIR')],\n",
    "        key=lambda x: int(x.replace('CIR', ''))\n",
    "    )\n",
    "    print(f\"  Samples: {len(df)}, CIR columns: {len(cir_cols)}\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # 1. Parse raw signal\n",
    "        sig = pd.to_numeric(row[cir_cols], errors='coerce').fillna(0).astype(float).values\n",
    "\n",
    "        # 2. PHYSICS NORMALIZATION: divide by RXPACC\n",
    "        rxpacc_col = 'RXPACC' if 'RXPACC' in row.index else 'RX_PACC'\n",
    "        rxpacc = float(row.get(rxpacc_col, 128.0))\n",
    "        if rxpacc > 0:\n",
    "            sig = sig / rxpacc\n",
    "\n",
    "        # 3. Smart ROI alignment\n",
    "        leading_edge = get_roi_alignment(sig)\n",
    "\n",
    "        # 4. Crop around leading edge\n",
    "        start = max(0, leading_edge - PRE)\n",
    "        end = start + TOTAL\n",
    "        if end > len(sig):\n",
    "            end = len(sig)\n",
    "            start = max(0, end - TOTAL)\n",
    "\n",
    "        crop = sig[start:end]\n",
    "        if len(crop) < TOTAL:\n",
    "            crop = np.pad(crop, (0, TOTAL - len(crop)), mode='constant')\n",
    "\n",
    "        # 5. Instance normalization [0, 1]\n",
    "        local_min = np.min(crop)\n",
    "        local_max = np.max(crop)\n",
    "        rng = local_max - local_min\n",
    "        if rng > 0:\n",
    "            crop = (crop - local_min) / rng\n",
    "        else:\n",
    "            crop = np.zeros(TOTAL)\n",
    "\n",
    "        processed_seqs.append(crop)\n",
    "        labels.append(float(row['Label']))\n",
    "\n",
    "    X = np.array(processed_seqs).reshape(-1, TOTAL, 1).astype(np.float32)\n",
    "    y = np.array(labels).astype(np.float32)\n",
    "\n",
    "    print(f\"  Output shape: X={X.shape}, y={y.shape}\")\n",
    "    print(f\"  LOS: {int(np.sum(y == 0))}, NLOS: {int(np.sum(y == 1))}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Load and split 70/15/15\n",
    "X_all, y_all = load_cir_dataset(\"../dataset/channels/combined_uwb_dataset.csv\")\n",
    "\n",
    "# 70/15/15 stratified split\n",
    "val_ratio = CONFIG[\"val_ratio\"]\n",
    "test_ratio = CONFIG[\"test_ratio\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_all, y_all,\n",
    "    test_size=val_ratio + test_ratio,\n",
    "    stratify=y_all,\n",
    "    random_state=CONFIG[\"seed\"]\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=test_ratio / (val_ratio + test_ratio),\n",
    "    stratify=y_temp,\n",
    "    random_state=CONFIG[\"seed\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit (70/15/15):\")\n",
    "print(f\"  Train: {X_train.shape[0]} (LOS: {int(np.sum(y_train==0))}, NLOS: {int(np.sum(y_train==1))})\")\n",
    "print(f\"  Val:   {X_val.shape[0]} (LOS: {int(np.sum(y_val==0))}, NLOS: {int(np.sum(y_val==1))})\")\n",
    "print(f\"  Test:  {X_test.shape[0]} (LOS: {int(np.sum(y_test==0))}, NLOS: {int(np.sum(y_test==1))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Model Architecture â€” PI-HLNN\n",
    "\n",
    "### Key Design: Input + State Driven Tau\n",
    "\n",
    "The time constant $\\tau_t$ at each timestep is controlled by both the current CIR sample $x_t$ and the hidden state $h_t$:\n",
    "\n",
    "$$\\tau_t = \\Delta t + \\text{softplus}\\big(f_\\tau([x_t, h_t])\\big)$$\n",
    "\n",
    "where $\\text{softplus}(z) = \\ln(1 + e^z)$.\n",
    "\n",
    "**Justification for the tau formulation:**\n",
    "- **No upper bound** â€” the network learns the appropriate time scale from data.\n",
    "- **Lower bound = $\\Delta t$** â€” this is the Euler discretization step. The ratio $\\Delta t / \\tau$ appears in the ODE denominator; keeping $\\tau \\geq \\Delta t$ ensures this ratio stays $\\leq 1$, which is required for stable Euler integration.\n",
    "- **Softplus** â€” smooth, always-positive activation that allows unconstrained gradient flow (unlike sigmoid which saturates).\n",
    "\n",
    "The ODE update (Euler discretization):\n",
    "\n",
    "$$h_{t+1} = \\frac{h_t + \\Delta t \\cdot S_t \\cdot A}{1 + \\Delta t / \\tau_t}$$\n",
    "\n",
    "Where $S_t = \\tanh(W_s \\cdot [x_t, h_t])$ is the synaptic activation and $A$ is a learnable decay parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass PILiquidCell(nn.Module):\n    \"\"\"\n    Conductance-based LTC cell (Hasani et al. 2020).\n    - Recurrent synapses: full conductance with reversal potentials\n    - Sensory synapses: gated additive input (direct injection)\n    - Softplus on conductances only (gleak, cm, w, sensory_w)\n    - ODE solved via semi-implicit Euler\n    \"\"\"\n    def __init__(self, input_size, hidden_size, ode_unfolds=6):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.input_size = input_size\n        self.ode_unfolds = ode_unfolds\n\n        # Neuron intrinsic parameters\n        self.gleak = nn.Parameter(torch.empty(hidden_size).uniform_(0.001, 1.0))\n        self.vleak = nn.Parameter(torch.empty(hidden_size).uniform_(-0.2, 0.2))\n        self.cm    = nn.Parameter(torch.empty(hidden_size).uniform_(0.4, 0.6))\n\n        # Recurrent synapses (conductance-based, h x h)\n        self.w     = nn.Parameter(torch.empty(hidden_size, hidden_size).uniform_(0.001, 1.0))\n        self.erev  = nn.Parameter(torch.empty(hidden_size, hidden_size).uniform_(-0.2, 0.2))\n        self.mu    = nn.Parameter(torch.empty(hidden_size, hidden_size).uniform_(0.3, 0.8))\n        self.sigma = nn.Parameter(torch.empty(hidden_size, hidden_size).uniform_(3, 8))\n\n        # Sensory synapses (gated input, input x h)\n        self.sensory_w     = nn.Parameter(torch.empty(input_size, hidden_size).uniform_(0.001, 1.0))\n        self.sensory_mu    = nn.Parameter(torch.empty(input_size, hidden_size).uniform_(0.3, 0.8))\n        self.sensory_sigma = nn.Parameter(torch.empty(input_size, hidden_size).uniform_(3, 8))\n\n    def forward(self, x_t, h_prev, dt=1.0):\n        # Positivity via softplus — conductances only (NOT sigma)\n        gleak = F.softplus(self.gleak)\n        cm    = F.softplus(self.cm)\n        w     = F.softplus(self.w)\n        sensory_w = F.softplus(self.sensory_w)\n\n        # Sensory current — gated additive input (computed once)\n        sensory_gate = torch.sigmoid(\n            self.sensory_sigma * (x_t.unsqueeze(-1) - self.sensory_mu)\n        )  # (batch, input, hidden)\n        sensory_current = (sensory_w * sensory_gate * x_t.unsqueeze(-1)).sum(dim=1)\n\n        # Semi-implicit Euler ODE integration\n        cm_t = cm / (dt / self.ode_unfolds)\n        v = h_prev\n\n        for _ in range(self.ode_unfolds):\n            recurrent_gate = torch.sigmoid(\n                self.sigma.unsqueeze(0) * (v.unsqueeze(2) - self.mu.unsqueeze(0))\n            )\n            w_gate = w.unsqueeze(0) * recurrent_gate\n            w_num = (w_gate * self.erev.unsqueeze(0)).sum(dim=1)\n            w_den = w_gate.sum(dim=1)\n\n            numerator   = cm_t * v + gleak * self.vleak + w_num + sensory_current\n            denominator = cm_t + gleak + w_den + 1e-8\n            v = numerator / denominator\n\n        tau = cm / (gleak + w_den + 1e-8)\n        return v, tau\n\n\nclass PI_HLNN(nn.Module):\n    def __init__(self, input_size=1, hidden_size=64, dropout=0.4, ode_unfolds=6):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.cell = PILiquidCell(input_size, hidden_size, ode_unfolds)\n        self.attn = nn.Linear(hidden_size, 1)\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, 32),\n            nn.SiLU(),\n            nn.Dropout(dropout),\n            nn.Linear(32, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x_seq, return_dynamics=False):\n        batch_size, seq_len, _ = x_seq.size()\n        h_t = torch.zeros(batch_size, self.hidden_size, device=x_seq.device)\n        h_states = []\n        tau_sum = torch.zeros_like(h_t)\n        tau_history = []\n        for t in range(seq_len):\n            h_t, tau_t = self.cell(x_seq[:, t, :], h_t)\n            h_states.append(h_t.unsqueeze(1))\n            tau_sum += tau_t\n            if return_dynamics:\n                tau_history.append(tau_t.unsqueeze(1))\n        h_all = torch.cat(h_states, dim=1)\n        attn_scores = self.attn(h_all).squeeze(-1)\n        attn_weights = F.softmax(attn_scores, dim=1).unsqueeze(-1)\n        h_pooled = (h_all * attn_weights).sum(dim=1)\n        tau_mean = tau_sum / seq_len\n        prediction = self.classifier(h_pooled)\n        if return_dynamics:\n            tau_hist = torch.cat(tau_history, dim=1)\n            return prediction, h_all, tau_hist, tau_mean\n        return prediction, tau_mean\n\n\n# Quick param count\ntest_model = PI_HLNN(input_size=1, hidden_size=64, ode_unfolds=6)\ntotal_params = sum(p.numel() for p in test_model.parameters())\nprint(f\"PI-HLNN parameter count: {total_params:,}\")\nprint(f\"  Recurrent (w, erev, mu, sigma): {4 * 64 * 64:,}\")\nprint(f\"  Sensory (w, mu, sigma):         {3 * 1 * 64:,}\")\nprint(f\"  Neuron (gleak, vleak, cm):      {3 * 64:,}\")\nprint(f\"  Attention:                      {64 + 1:,}\")\nprint(f\"  Classifier:                     {64*32+32 + 32*1+1:,}\")\ndel test_model"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Loss Function\n",
    "\n",
    "$$\\mathcal{L} = \\mathcal{L}_{BCE}$$\n",
    "\n",
    "Pure binary cross-entropy. The time constant $\\tau$ is **not** constrained by the loss â€” it emerges entirely from the ODE dynamics driven by `[x_t, h_t]`. This lets the LNN discover its own temporal behavior from the signal.\n",
    "\n",
    "The tau values are still computed and available for post-training diagnostics (tau distribution, temporal evolution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: Binary Cross-Entropy (pure BCE, no tau constraint)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# LOSS FUNCTION (Pure BCE)\n",
    "# ==========================================\n",
    "criterion_fn = nn.BCELoss()\n",
    "\n",
    "print(\"Loss: Binary Cross-Entropy (pure BCE, no tau constraint)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Training Pipeline (70/15/15 Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==========================================\n# TRAINING PIPELINE (70/15/15)\n# ==========================================\nimport math\n\ndef train_model(X_train, y_train, X_val, y_val, config=CONFIG):\n    print(f\"Training on {len(X_train)} samples, validating on {len(X_val)}\")\n\n    # Prepare tensors\n    X_tr = torch.tensor(X_train).to(device)\n    y_tr = torch.tensor(y_train).unsqueeze(1).to(device)\n    X_va = torch.tensor(X_val).to(device)\n    y_va = torch.tensor(y_val).unsqueeze(1).to(device)\n\n    train_ds = TensorDataset(X_tr, y_tr)\n    train_loader = DataLoader(train_ds, batch_size=config[\"batch_size\"], shuffle=True)\n\n    # Initialize model\n    model = PI_HLNN(\n        input_size=config[\"input_size\"],\n        hidden_size=config[\"hidden_size\"],\n        dropout=config[\"dropout\"],\n        ode_unfolds=config.get(\"ode_unfolds\", 6)\n    ).to(device)\n\n    criterion = nn.BCELoss()\n\n    optimizer = optim.AdamW(\n        model.parameters(),\n        lr=config[\"lr\"],\n        weight_decay=config[\"weight_decay\"]\n    )\n\n    # Warmup + Cosine Annealing scheduler\n    warmup_epochs = config[\"warmup_epochs\"]\n    total_epochs = config[\"max_epochs\"]\n\n    def lr_lambda(epoch):\n        if epoch < warmup_epochs:\n            return (epoch + 1) / warmup_epochs\n        progress = (epoch - warmup_epochs) / max(1, total_epochs - warmup_epochs)\n        return max(0.01, 0.5 * (1.0 + math.cos(math.pi * progress)))\n\n    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n    # Training history\n    history = {\n        \"train_loss\": [], \"val_loss\": [],\n        \"train_acc\": [], \"val_acc\": [],\n        \"lr\": []\n    }\n\n    best_val_acc = 0\n    best_model_state = None\n    patience_counter = 0\n\n    for epoch in range(config[\"max_epochs\"]):\n        # --- TRAIN ---\n        model.train()\n        train_loss_sum = 0\n        train_correct, train_total = 0, 0\n\n        for batch_x, batch_y in train_loader:\n            optimizer.zero_grad()\n            pred, tau_mean = model(batch_x)\n            loss = criterion(pred, batch_y)\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), config[\"grad_clip\"])\n            optimizer.step()\n\n            train_loss_sum += loss.item() * len(batch_x)\n            train_correct += ((pred > 0.5).float() == batch_y).sum().item()\n            train_total += len(batch_x)\n\n        train_loss = train_loss_sum / train_total\n        train_acc = train_correct / train_total\n\n        # --- VALIDATE ---\n        model.eval()\n        with torch.no_grad():\n            val_pred, val_tau = model(X_va)\n            val_loss = criterion(val_pred, y_va)\n            val_acc = ((val_pred > 0.5).float() == y_va).float().mean().item()\n\n        lr_now = optimizer.param_groups[0]['lr']\n\n        # Record history\n        history[\"train_loss\"].append(train_loss)\n        history[\"val_loss\"].append(val_loss.item())\n        history[\"train_acc\"].append(train_acc)\n        history[\"val_acc\"].append(val_acc)\n        history[\"lr\"].append(lr_now)\n\n        scheduler.step()\n\n        # Early stopping\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = copy.deepcopy(model.state_dict())\n            patience_counter = 0\n        else:\n            patience_counter += 1\n\n        if epoch % 5 == 0 or epoch == config[\"max_epochs\"] - 1:\n            print(f\"  Ep {epoch:>3} | Loss: {train_loss:.4f} | \"\n                  f\"Val Acc: {100*val_acc:.2f}% | \"\n                  f\"Best: {100*best_val_acc:.2f}% | LR: {lr_now:.1e}\")\n\n        if patience_counter >= config[\"patience\"]:\n            print(f\"  Early stopping at epoch {epoch} (patience={config['patience']})\")\n            break\n\n    # Load best model\n    model.load_state_dict(best_model_state)\n    print(f\"\\nBest Validation Accuracy: {100*best_val_acc:.2f}%\")\n\n    return model, (X_va, y_va), history\n\n\n# Run training\nbest_model, best_data, best_history = train_model(X_train, y_train, X_val, y_val)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# DIAGNOSTIC GRID (3x2)\n",
    "# ==========================================\n",
    "def plot_diagnostics(model, val_data, history):\n",
    "    X_va, y_va = val_data\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds, h_hist, tau_hist, tau_mean = model(X_va, return_dynamics=True)\n",
    "    \n",
    "    y_true = y_va.cpu().numpy().flatten()\n",
    "    y_prob = preds.cpu().numpy().flatten()\n",
    "    y_pred = (y_prob > 0.5).astype(float)\n",
    "    tau_mean_np = tau_mean.cpu().numpy().mean(axis=1)  # (batch,)\n",
    "    h_hist_np = h_hist.cpu().numpy()\n",
    "    tau_hist_np = tau_hist.cpu().numpy()\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 3, figsize=(24, 14))\n",
    "    plt.subplots_adjust(hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # --- 1. LEARNING CURVES ---\n",
    "    ax = axs[0, 0]\n",
    "    ax.plot(history[\"train_loss\"], label='Train Loss', color='#3498db', lw=2)\n",
    "    ax.plot(history[\"val_loss\"], label='Val Loss', color='#e74c3c', lw=2, ls='--')\n",
    "    ax.set_title(\"Learning Curves\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss (BCE)\")\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # --- 2. ACCURACY CURVES ---\n",
    "    ax = axs[0, 1]\n",
    "    ax.plot(history[\"train_acc\"], label='Train Acc', color='#3498db', lw=2)\n",
    "    ax.plot(history[\"val_acc\"], label='Val Acc', color='#e74c3c', lw=2, ls='--')\n",
    "    ax.set_title(\"Accuracy Curves\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_ylim([0.4, 1.05])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # --- 3. CONFUSION MATRIX ---\n",
    "    ax = axs[0, 2]\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=['LOS', 'NLOS'])\n",
    "    disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    ax.set_title(f\"Confusion Matrix (Acc: {100*acc:.1f}%)\")\n",
    "    \n",
    "    # --- 4. ROC CURVE ---\n",
    "    ax = axs[1, 0]\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, color='#e74c3c', lw=2, label=f'AUC = {roc_auc:.4f}')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.5)\n",
    "    ax.set_title(\"ROC Curve\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # --- 5. PCA PHASE SPACE ---\n",
    "    ax = axs[1, 1]\n",
    "    batch_size, seq_len, hidden_dim = h_hist_np.shape\n",
    "    \n",
    "    los_idx = np.where(y_true == 0)[0]\n",
    "    nlos_idx = np.where(y_true == 1)[0]\n",
    "    n_show = min(len(los_idx), len(nlos_idx), 25)\n",
    "    show_idx = np.concatenate([los_idx[:n_show], nlos_idx[:n_show]])\n",
    "    \n",
    "    h_flat = h_hist_np.reshape(-1, hidden_dim)\n",
    "    pca = PCA(n_components=2)\n",
    "    h_pca = pca.fit_transform(h_flat).reshape(batch_size, seq_len, 2)\n",
    "    \n",
    "    for i in show_idx:\n",
    "        color = '#2ecc71' if y_true[i] == 0 else '#e74c3c'\n",
    "        ax.plot(h_pca[i, :, 0], h_pca[i, :, 1], color=color, alpha=0.3, lw=0.8)\n",
    "        ax.scatter(h_pca[i, -1, 0], h_pca[i, -1, 1], color=color, s=15, zorder=5)\n",
    "    \n",
    "    ax.set_title(f\"Liquid State Phase Space (PCA, n={n_show*2})\")\n",
    "    ax.set_xlabel(f\"PC1 ({100*pca.explained_variance_ratio_[0]:.1f}%)\")\n",
    "    ax.set_ylabel(f\"PC2 ({100*pca.explained_variance_ratio_[1]:.1f}%)\")\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    \n",
    "    # --- 6. TAU DISTRIBUTION (emergent, no targets) ---\n",
    "    ax = axs[1, 2]\n",
    "    sns.kdeplot(tau_mean_np[y_true == 0], ax=ax, fill=True, color='#2ecc71',\n",
    "                label=f'LOS (mean={tau_mean_np[y_true==0].mean():.2f})', alpha=0.6)\n",
    "    sns.kdeplot(tau_mean_np[y_true == 1], ax=ax, fill=True, color='#e74c3c',\n",
    "                label=f'NLOS (mean={tau_mean_np[y_true==1].mean():.2f})', alpha=0.6)\n",
    "    ax.set_title(\"Emergent Time Constants (Tau)\")\n",
    "    ax.set_xlabel(\"Mean Tau\")\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(\"PI-HLNN Stage 1 Diagnostics\", fontsize=16, fontweight='bold', y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_diagnostics(best_model, best_data, best_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# TAU TEMPORAL EVOLUTION\n",
    "# ==========================================\n",
    "def plot_tau_temporal(model, val_data, n_samples=5):\n",
    "    \"\"\"\n",
    "    Show how tau evolves across the 60 timesteps for individual samples.\n",
    "    This reveals the real-time adaptation of dynamics to the signal shape.\n",
    "    \"\"\"\n",
    "    X_va, y_va = val_data\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, _, tau_hist, _ = model(X_va, return_dynamics=True)\n",
    "    \n",
    "    y_true = y_va.cpu().numpy().flatten()\n",
    "    tau_hist_np = tau_hist.cpu().numpy()  # (batch, seq_len, hidden)\n",
    "    # Average across neurons for each timestep\n",
    "    tau_temporal = tau_hist_np.mean(axis=2)  # (batch, seq_len)\n",
    "    x_input = X_va.cpu().numpy().squeeze(-1)  # (batch, seq_len)\n",
    "    \n",
    "    los_idx = np.where(y_true == 0)[0][:n_samples]\n",
    "    nlos_idx = np.where(y_true == 1)[0][:n_samples]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(18, 10))\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "    \n",
    "    # --- LOS: Signal + Tau ---\n",
    "    ax = axs[0, 0]\n",
    "    for i in los_idx:\n",
    "        ax.plot(x_input[i], alpha=0.5, color='#2ecc71', lw=1.2)\n",
    "    ax.set_title(f\"LOS Signals (n={len(los_idx)})\")\n",
    "    ax.set_xlabel(\"Timestep\")\n",
    "    ax.set_ylabel(\"Normalized CIR\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = axs[0, 1]\n",
    "    for i in los_idx:\n",
    "        ax.plot(tau_temporal[i], alpha=0.5, color='#2ecc71', lw=1.2)\n",
    "    ax.set_title(f\"LOS Tau Evolution\")\n",
    "    ax.set_xlabel(\"Timestep\")\n",
    "    ax.set_ylabel(\"Mean Tau\")\n",
    "    ax.set_ylim([0.5, 6.5])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # --- NLOS: Signal + Tau ---\n",
    "    ax = axs[1, 0]\n",
    "    for i in nlos_idx:\n",
    "        ax.plot(x_input[i], alpha=0.5, color='#e74c3c', lw=1.2)\n",
    "    ax.set_title(f\"NLOS Signals (n={len(nlos_idx)})\")\n",
    "    ax.set_xlabel(\"Timestep\")\n",
    "    ax.set_ylabel(\"Normalized CIR\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = axs[1, 1]\n",
    "    for i in nlos_idx:\n",
    "        ax.plot(tau_temporal[i], alpha=0.5, color='#e74c3c', lw=1.2)\n",
    "    ax.set_title(f\"NLOS Tau Evolution\")\n",
    "    ax.set_xlabel(\"Timestep\")\n",
    "    ax.set_ylabel(\"Mean Tau\")\n",
    "    ax.set_ylim([0.5, 6.5])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(\"Tau Temporal Evolution: How Dynamics Adapt to Signal Shape\",\n",
    "                 fontsize=14, fontweight='bold', y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_tau_temporal(best_model, best_data, n_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Test Set Evaluation & Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.11%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOS       0.94      0.98      0.96       270\n",
      "        NLOS       0.98      0.94      0.96       270\n",
      "\n",
      "    accuracy                           0.96       540\n",
      "   macro avg       0.96      0.96      0.96       540\n",
      "weighted avg       0.96      0.96      0.96       540\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# TEST SET EVALUATION\n",
    "# ==========================================\n",
    "best_model.eval()\n",
    "X_te = torch.tensor(X_test).to(device)\n",
    "y_te = torch.tensor(y_test).unsqueeze(1).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_pred, _ = best_model(X_te)\n",
    "    test_acc = ((test_pred > 0.5).float() == y_te).float().mean().item()\n",
    "    test_pred_np = (test_pred.cpu().numpy().flatten() > 0.5).astype(float)\n",
    "    test_true_np = y_test.flatten()\n",
    "\n",
    "print(f\"Test Accuracy: {100*test_acc:.2f}%\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(test_true_np, test_pred_np, target_names=['LOS', 'NLOS']))\n",
    "\n",
    "# Test confusion matrix\n",
    "cm = confusion_matrix(test_true_np, test_pred_np)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['LOS', 'NLOS'])\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "ax.set_title(f\"Test Set Confusion Matrix (Acc: {100*test_acc:.1f}%)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: stage1_pi_hlnn_best.pt\n",
      "Saved: stage1_config.pt\n",
      "\n",
      "Artifacts ready for Stage 2.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# SAVE ARTIFACTS\n",
    "# ==========================================\n",
    "# 1. Model weights\n",
    "torch.save(best_model.state_dict(), \"stage1_pi_hlnn_best.pt\")\n",
    "print(\"Saved: stage1_pi_hlnn_best.pt\")\n",
    "\n",
    "# 2. Configuration (for reproducibility)\n",
    "torch.save({\"config\": CONFIG}, \"stage1_config.pt\")\n",
    "print(\"Saved: stage1_config.pt\")\n",
    "\n",
    "print(f\"\\nArtifacts ready for Stage 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 complete.\n",
      "Model artifact: stage1_pi_hlnn_best.pt\n",
      "Config artifact: stage1_config.pt\n",
      "\n",
      "Ready for Stage 2.\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 1 complete.\")\n",
    "print(\"Model artifact: stage1_pi_hlnn_best.pt\")\n",
    "print(\"Config artifact: stage1_config.pt\")\n",
    "print(\"\\nReady for Stage 2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}