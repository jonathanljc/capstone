{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Stage 1: BERT + FP — LOS / NLOS Classification\n## Transformer Encoder with FP_AMPL Prefix Token Conditioning\n\n**Purpose**: BERT with FP_AMPL1/2/3 conditioning — fair comparison against LNN+FP where all models receive identical input.\n\n**FP Integration (Prefix Token)**: FP_AMPL1/2/3 → Linear(3→d_model) → prepended as a prefix token before the CIR sequence. The Transformer's self-attention then cross-references the static FP features with every CIR timestep — the most natural integration for attention-based architectures.\n\n| | BERT+FP (this) | BERT (CIR only) | LNN+FP | LSTM+FP |\n|---|---|---|---|---|\n| Input | CIR + FP_AMPL | CIR only | CIR + FP_AMPL | CIR + FP_AMPL |\n| FP usage | Prefix token (self-attn) | None | ODE h₀ init | LSTM h₀/c₀ init |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CONFIG = {\n    \"pre_crop\": 10,\n    \"post_crop\": 50,\n    \"total_len\": 60,\n    \"search_start\": 740,\n    \"search_end\": 890,\n    \"d_model\": 64,\n    \"nhead\": 4,\n    \"num_layers\": 2,\n    \"dim_feedforward\": 128,\n    \"input_size\": 1,\n    \"fp_size\": 3,\n    \"dropout\": 0.2,\n    \"batch_size\": 64,\n    \"max_epochs\": 40,\n    \"lr\": 1e-3,\n    \"weight_decay\": 1e-4,\n    \"warmup_epochs\": 3,\n    \"patience\": 10,\n    \"grad_clip\": 1.0,\n    \"val_ratio\": 0.15,\n    \"test_ratio\": 0.15,\n    \"seed\": 42,\n}"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    classification_report, roc_curve, auc\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Data Loading, ROI Alignment & 70/15/15 Split\n",
    "\n",
    "Same CIR preprocessing as all other models. **Now includes FP_AMPL1/2/3 extraction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ../dataset/channels/combined_uwb_dataset.csv\n",
      "  Samples: 3600, CIR columns: 1016\n",
      "  Output shape: X=(3600, 60, 1), y=(3600,), F=(3600, 3)\n",
      "  LOS: 1800, NLOS: 1800\n",
      "\n",
      "Split (70/15/15):\n",
      "  Train: 2520 (LOS: 1260, NLOS: 1260)\n",
      "  Val:   540 (LOS: 270, NLOS: 270)\n",
      "  Test:  540 (LOS: 270, NLOS: 270)\n"
     ]
    }
   ],
   "source": [
    "def get_roi_alignment(sig, search_start=CONFIG[\"search_start\"],\n",
    "                      search_end=CONFIG[\"search_end\"]):\n",
    "    region = sig[search_start:search_end]\n",
    "    if len(region) == 0:\n",
    "        return np.argmax(sig)\n",
    "    peak_local = np.argmax(region)\n",
    "    peak_idx = search_start + peak_local\n",
    "    peak_val = sig[peak_idx]\n",
    "    noise_section = sig[:search_start]\n",
    "    if len(noise_section) > 10:\n",
    "        noise_mean = np.mean(noise_section)\n",
    "        noise_std = np.std(noise_section)\n",
    "        threshold = max(noise_mean + 3 * noise_std, 0.05 * peak_val)\n",
    "    else:\n",
    "        threshold = 0.05 * peak_val\n",
    "    leading_edge = peak_idx\n",
    "    for i in range(peak_idx, max(search_start - 20, 0), -1):\n",
    "        if sig[i] < threshold:\n",
    "            leading_edge = i + 1\n",
    "            break\n",
    "    return leading_edge\n",
    "\n",
    "\n",
    "def load_cir_fp_dataset(filepath=\"../dataset/channels/combined_uwb_dataset.csv\"):\n",
    "    \"\"\"Returns: X (N, 60, 1), y (N,), F (N, 3) — CIR + FP_AMPL features.\"\"\"\n",
    "    PRE = CONFIG[\"pre_crop\"]\n",
    "    TOTAL = CONFIG[\"total_len\"]\n",
    "    processed_seqs, labels, fp_features = [], [], []\n",
    "\n",
    "    print(f\"Loading: {filepath}\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    cir_cols = sorted(\n",
    "        [c for c in df.columns if c.startswith('CIR')],\n",
    "        key=lambda x: int(x.replace('CIR', ''))\n",
    "    )\n",
    "    print(f\"  Samples: {len(df)}, CIR columns: {len(cir_cols)}\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sig = pd.to_numeric(row[cir_cols], errors='coerce').fillna(0).astype(float).values\n",
    "        rxpacc_col = 'RXPACC' if 'RXPACC' in row.index else 'RX_PACC'\n",
    "        rxpacc = float(row.get(rxpacc_col, 128.0))\n",
    "        if rxpacc > 0:\n",
    "            sig = sig / rxpacc\n",
    "\n",
    "        f1 = float(row.get('FP_AMPL1', 0)) / max(rxpacc, 1) / 64.0\n",
    "        f2 = float(row.get('FP_AMPL2', 0)) / max(rxpacc, 1) / 64.0\n",
    "        f3 = float(row.get('FP_AMPL3', 0)) / max(rxpacc, 1) / 64.0\n",
    "        fp_features.append([f1, f2, f3])\n",
    "\n",
    "        leading_edge = get_roi_alignment(sig)\n",
    "        start = max(0, leading_edge - PRE)\n",
    "        end = start + TOTAL\n",
    "        if end > len(sig):\n",
    "            end = len(sig)\n",
    "            start = max(0, end - TOTAL)\n",
    "        crop = sig[start:end]\n",
    "        if len(crop) < TOTAL:\n",
    "            crop = np.pad(crop, (0, TOTAL - len(crop)), mode='constant')\n",
    "        local_min, local_max = np.min(crop), np.max(crop)\n",
    "        rng = local_max - local_min\n",
    "        crop = (crop - local_min) / rng if rng > 0 else np.zeros(TOTAL)\n",
    "\n",
    "        processed_seqs.append(crop)\n",
    "        labels.append(float(row['Label']))\n",
    "\n",
    "    X = np.array(processed_seqs).reshape(-1, TOTAL, 1).astype(np.float32)\n",
    "    y = np.array(labels).astype(np.float32)\n",
    "    F = np.array(fp_features).astype(np.float32)\n",
    "    print(f\"  Output shape: X={X.shape}, y={y.shape}, F={F.shape}\")\n",
    "    print(f\"  LOS: {int(np.sum(y == 0))}, NLOS: {int(np.sum(y == 1))}\")\n",
    "    return X, y, F\n",
    "\n",
    "\n",
    "X_all, y_all, F_all = load_cir_fp_dataset(\"../dataset/channels/combined_uwb_dataset.csv\")\n",
    "\n",
    "indices = np.arange(len(y_all))\n",
    "idx_train, idx_temp = train_test_split(\n",
    "    indices, test_size=CONFIG[\"val_ratio\"] + CONFIG[\"test_ratio\"],\n",
    "    stratify=y_all, random_state=CONFIG[\"seed\"]\n",
    ")\n",
    "idx_val, idx_test = train_test_split(\n",
    "    idx_temp, test_size=CONFIG[\"test_ratio\"] / (CONFIG[\"val_ratio\"] + CONFIG[\"test_ratio\"]),\n",
    "    stratify=y_all[idx_temp], random_state=CONFIG[\"seed\"]\n",
    ")\n",
    "\n",
    "X_train, y_train, F_train = X_all[idx_train], y_all[idx_train], F_all[idx_train]\n",
    "X_val,   y_val,   F_val   = X_all[idx_val],   y_all[idx_val],   F_all[idx_val]\n",
    "X_test,  y_test,  F_test  = X_all[idx_test],  y_all[idx_test],  F_all[idx_test]\n",
    "\n",
    "print(f\"\\nSplit (70/15/15):\")\n",
    "print(f\"  Train: {X_train.shape[0]} (LOS: {int(np.sum(y_train==0))}, NLOS: {int(np.sum(y_train==1))})\")\n",
    "print(f\"  Val:   {X_val.shape[0]} (LOS: {int(np.sum(y_val==0))}, NLOS: {int(np.sum(y_val==1))})\")\n",
    "print(f\"  Test:  {X_test.shape[0]} (LOS: {int(np.sum(y_test==0))}, NLOS: {int(np.sum(y_test==1))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Section 3: BERT + FP Model Architecture (Prefix Token)\n\nSame Transformer Encoder as CIR-only BERT, but FP_AMPL1/2/3 is projected to `d_model` dimensions and **prepended as a prefix token** before the CIR sequence. Self-attention then cross-references the static FP features with every CIR timestep.\n\n```\nFP_AMPL (3) → Linear(3→64) → fp_token (1, 64)\n                                    ↓\nCIR (60,1) → Linear(1→64) → [CLS, FP_TOKEN, CIR₁, ..., CIR₆₀] (62 tokens)\n                                    ↓\n                          + Positional Embeddings\n                                    ↓\n                    TransformerEncoder (2 layers, 4 heads)\n                                    ↓\n                     CLS output → LayerNorm → 64-dim\n                                    ↓\n               Linear(64→32) → SiLU → Dropout → Linear(32→1) → Sigmoid\n```\n\n**Why prefix tokens?** This is the most natural FP integration for attention architectures:\n- FP features participate in **every self-attention layer**, not just at the output\n- Each CIR timestep can attend to the FP token to modulate its representation\n- The CLS token aggregates both FP and CIR information through multi-head attention\n- Analogous to how BERT uses special tokens ([SEP], [CLS]) to encode structure"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class BERT_FP_Classifier(nn.Module):\n    \"\"\"\n    BERT-style Transformer Encoder with FP_AMPL prefix token conditioning.\n\n    FP_AMPL1/2/3 are projected to d_model dimensions and prepended to the\n    CIR sequence as a \"prefix token\" before self-attention, allowing the\n    Transformer to cross-reference the static FP features with every CIR\n    timestep through multi-head attention.\n\n    Sequence layout: [CLS, FP_TOKEN, CIR_1, ..., CIR_60] = 62 tokens\n    \"\"\"\n    def __init__(self, input_size=1, d_model=64, nhead=4, num_layers=2,\n                 dim_feedforward=128, dropout=0.2, max_seq_len=60, fp_size=3):\n        super().__init__()\n        self.d_model = d_model\n\n        # Input projection: scalar CIR value -> d_model\n        self.input_proj = nn.Linear(input_size, d_model)\n\n        # Learnable CLS token\n        self.cls_token = nn.Parameter(torch.randn(1, 1, d_model) * 0.02)\n\n        # FP prefix token projection: (3,) -> (d_model,)\n        self.fp_proj = nn.Linear(fp_size, d_model)\n\n        # Learnable positional embeddings: CLS + FP_prefix + max_seq_len CIR tokens\n        self.pos_embed = nn.Parameter(torch.randn(1, max_seq_len + 2, d_model) * 0.02)\n\n        # Transformer encoder\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,\n            dropout=dropout, batch_first=True, activation='gelu',\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n\n        # Layer norm on CLS output\n        self.norm = nn.LayerNorm(d_model)\n\n        # Classifier head (d_model input — FP is already fused via attention)\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model, 32),\n            nn.SiLU(),\n            nn.Dropout(dropout),\n            nn.Linear(32, 1),\n            nn.Sigmoid()\n        )\n\n    def _encode(self, x_seq, fp_features=None):\n        \"\"\"Shared encoder: CIR + optional FP prefix -> transformer hidden states.\"\"\"\n        batch_size = x_seq.size(0)\n\n        # Project CIR input: (B, 60, 1) -> (B, 60, d_model)\n        x = self.input_proj(x_seq)\n\n        # Prepend CLS token\n        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n\n        if fp_features is not None:\n            # Project FP to d_model and treat as prefix token: (B, 3) -> (B, 1, d_model)\n            fp_token = self.fp_proj(fp_features).unsqueeze(1)\n            # Sequence: [CLS, FP_TOKEN, CIR_1, ..., CIR_60] -> (B, 62, d_model)\n            x = torch.cat([cls_tokens, fp_token, x], dim=1)\n        else:\n            # No FP: [CLS, CIR_1, ..., CIR_60] -> (B, 61, d_model)\n            x = torch.cat([cls_tokens, x], dim=1)\n\n        # Add positional embeddings (sliced to actual sequence length)\n        x = x + self.pos_embed[:, :x.size(1), :]\n\n        # Transformer encoder\n        h_all = self.transformer(x)\n        return h_all\n\n    def forward(self, x_seq, fp_features=None, return_dynamics=False):\n        h_all = self._encode(x_seq, fp_features)\n\n        # CLS token output as pooled representation\n        cls_out = self.norm(h_all[:, 0, :])  # (B, d_model)\n\n        pred = self.classifier(cls_out)\n\n        if return_dynamics:\n            return pred, h_all\n        return pred\n\n    def embed(self, x_seq, fp_features=None):\n        \"\"\"Return d_model-dim embedding for Stage 2/3 compatibility.\"\"\"\n        h_all = self._encode(x_seq, fp_features)\n        return self.norm(h_all[:, 0, :])  # (B, d_model)\n\n\n_m = BERT_FP_Classifier(\n    input_size=CONFIG[\"input_size\"], d_model=CONFIG[\"d_model\"],\n    nhead=CONFIG[\"nhead\"], num_layers=CONFIG[\"num_layers\"],\n    dim_feedforward=CONFIG[\"dim_feedforward\"],\n    fp_size=CONFIG[\"fp_size\"],\n)\n_total = sum(p.numel() for p in _m.parameters())\nprint(f\"BERT_FP_Classifier parameter count: {_total:,}\")\nprint(f\"  Input projection:     {sum(p.numel() for p in _m.input_proj.parameters()):,}\")\nprint(f\"  CLS token:            {_m.cls_token.numel():,}\")\nprint(f\"  FP prefix projection: {sum(p.numel() for p in _m.fp_proj.parameters()):,}\")\nprint(f\"  Positional embeddings:{_m.pos_embed.numel():,} (62 positions: CLS + FP + 60 CIR)\")\nprint(f\"  Transformer encoder:  {sum(p.numel() for p in _m.transformer.parameters()):,}\")\nprint(f\"  Layer norm:           {sum(p.numel() for p in _m.norm.parameters()):,}\")\nprint(f\"  Classifier:           {sum(p.numel() for p in _m.classifier.parameters()):,}\")\nprint(f\"  Embedding dim: {_m.d_model}\")\nprint(f\"\\n  FP conditioning: prefix token (goes through self-attention)\")\ndel _m"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Training Pipeline\n",
    "\n",
    "Same training config as all other models: AdamW, cosine LR with warmup, early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_model(X_train, y_train, X_val, y_val, F_train, F_val, config=CONFIG):\n    print(f\"Training on {len(X_train)} samples, validating on {len(X_val)}\")\n    print(f\"  Input: CIR + FP_AMPL prefix token (F_train={F_train.shape})\")\n\n    X_tr = torch.tensor(X_train).to(device)\n    y_tr = torch.tensor(y_train).unsqueeze(1).to(device)\n    X_va = torch.tensor(X_val).to(device)\n    y_va = torch.tensor(y_val).unsqueeze(1).to(device)\n    F_tr = torch.tensor(F_train).to(device)\n    F_va = torch.tensor(F_val).to(device)\n\n    train_ds = TensorDataset(X_tr, y_tr, F_tr)\n    train_loader = DataLoader(train_ds, batch_size=config[\"batch_size\"], shuffle=True)\n\n    model = BERT_FP_Classifier(\n        input_size=config[\"input_size\"], d_model=config[\"d_model\"],\n        nhead=config[\"nhead\"], num_layers=config[\"num_layers\"],\n        dim_feedforward=config[\"dim_feedforward\"], dropout=config[\"dropout\"],\n        max_seq_len=config[\"total_len\"],\n        fp_size=config[\"fp_size\"],\n    ).to(device)\n\n    criterion = nn.BCELoss()\n    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n\n    warmup_epochs = config[\"warmup_epochs\"]\n    total_epochs  = config[\"max_epochs\"]\n\n    def lr_lambda(epoch):\n        if epoch < warmup_epochs:\n            return (epoch + 1) / warmup_epochs\n        progress = (epoch - warmup_epochs) / max(1, total_epochs - warmup_epochs)\n        return max(0.01, 0.5 * (1.0 + math.cos(math.pi * progress)))\n\n    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": [], \"lr\": []}\n    best_val_acc = 0\n    best_model_state = None\n    patience_counter = 0\n\n    for epoch in range(config[\"max_epochs\"]):\n        model.train()\n        train_loss_sum = 0\n        train_correct, train_total = 0, 0\n\n        for batch_x, batch_y, batch_f in train_loader:\n            optimizer.zero_grad()\n            pred = model(batch_x, fp_features=batch_f)\n            loss = criterion(pred, batch_y)\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), config[\"grad_clip\"])\n            optimizer.step()\n            train_loss_sum += loss.item() * len(batch_x)\n            train_correct  += ((pred > 0.5).float() == batch_y).sum().item()\n            train_total    += len(batch_x)\n\n        train_loss = train_loss_sum / train_total\n        train_acc  = train_correct / train_total\n\n        model.eval()\n        with torch.no_grad():\n            val_pred = model(X_va, fp_features=F_va)\n            val_loss = criterion(val_pred, y_va)\n            val_acc  = ((val_pred > 0.5).float() == y_va).float().mean().item()\n\n        lr_now = optimizer.param_groups[0][\"lr\"]\n        history[\"train_loss\"].append(train_loss)\n        history[\"val_loss\"].append(val_loss.item())\n        history[\"train_acc\"].append(train_acc)\n        history[\"val_acc\"].append(val_acc)\n        history[\"lr\"].append(lr_now)\n\n        scheduler.step()\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = copy.deepcopy(model.state_dict())\n            patience_counter = 0\n        else:\n            patience_counter += 1\n\n        if epoch % 5 == 0 or epoch == config[\"max_epochs\"] - 1:\n            print(f\"  Ep {epoch:>3} | Loss: {train_loss:.4f} | Val Acc: {100*val_acc:.2f}% | Best: {100*best_val_acc:.2f}% | LR: {lr_now:.1e}\")\n\n        if patience_counter >= config[\"patience\"]:\n            print(f\"  Early stopping at epoch {epoch}\")\n            break\n\n    model.load_state_dict(best_model_state)\n    print(f\"\\nBest Validation Accuracy: {100*best_val_acc:.2f}%\")\n    return model, (X_va, y_va, F_va), history\n\n\nbest_model, best_data, best_history = train_model(X_train, y_train, X_val, y_val, F_train, F_val)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_diagnostics(model, val_data, history):\n    X_va, y_va, F_va = val_data\n    model.eval()\n    with torch.no_grad():\n        preds, h_all = model(X_va, fp_features=F_va, return_dynamics=True)\n\n    y_true = y_va.cpu().numpy().flatten()\n    y_prob = preds.cpu().numpy().flatten()\n    y_pred = (y_prob > 0.5).astype(float)\n    # Skip CLS (idx 0) + FP prefix token (idx 1) → CIR hidden states only\n    h_hist = h_all[:, 2:, :].cpu().numpy()\n\n    fig, axs = plt.subplots(2, 3, figsize=(24, 14))\n    plt.subplots_adjust(hspace=0.35, wspace=0.3)\n\n    ax = axs[0, 0]\n    ax.plot(history[\"train_loss\"], label=\"Train Loss\", color=\"#3498db\", lw=2)\n    ax.plot(history[\"val_loss\"],   label=\"Val Loss\",   color=\"#e74c3c\", lw=2, ls=\"--\")\n    ax.set_title(\"Learning Curves\"); ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"Loss (BCE)\")\n    ax.legend(fontsize=9); ax.grid(True, alpha=0.3)\n\n    ax = axs[0, 1]\n    ax.plot(history[\"train_acc\"], label=\"Train Acc\", color=\"#3498db\", lw=2)\n    ax.plot(history[\"val_acc\"],   label=\"Val Acc\",   color=\"#e74c3c\", lw=2, ls=\"--\")\n    ax.set_title(\"Accuracy Curves\"); ax.set_xlabel(\"Epoch\"); ax.set_ylabel(\"Accuracy\")\n    ax.set_ylim([0.4, 1.05]); ax.legend(); ax.grid(True, alpha=0.3)\n\n    ax = axs[0, 2]\n    cm = confusion_matrix(y_true, y_pred)\n    disp = ConfusionMatrixDisplay(cm, display_labels=[\"LOS\", \"NLOS\"])\n    disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n    acc = (y_true == y_pred).mean()\n    ax.set_title(f\"Confusion Matrix (Acc: {100*acc:.1f}%)\")\n\n    ax = axs[1, 0]\n    fpr, tpr, _ = roc_curve(y_true, y_prob)\n    roc_auc = auc(fpr, tpr)\n    ax.plot(fpr, tpr, color=\"#e74c3c\", lw=2, label=f\"AUC = {roc_auc:.4f}\")\n    ax.plot([0, 1], [0, 1], \"k--\", lw=1, alpha=0.5)\n    ax.set_title(\"ROC Curve\"); ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\")\n    ax.legend(loc=\"lower right\"); ax.grid(True, alpha=0.3)\n\n    ax = axs[1, 1]\n    batch_size, seq_len, h = h_hist.shape\n    los_idx  = np.where(y_true == 0)[0]\n    nlos_idx = np.where(y_true == 1)[0]\n    n_show   = min(len(los_idx), len(nlos_idx), 25)\n    show_idx = np.concatenate([los_idx[:n_show], nlos_idx[:n_show]])\n    h_flat = h_hist.reshape(-1, h)\n    scaler = StandardScaler()\n    h_flat_scaled = scaler.fit_transform(h_flat)\n    pca = PCA(n_components=2)\n    h_pca = pca.fit_transform(h_flat_scaled).reshape(batch_size, seq_len, 2)\n    for i in [j for j in show_idx if y_true[j] == 1]:\n        ax.plot(h_pca[i, :, 0], h_pca[i, :, 1], color=\"#e74c3c\", alpha=0.3, lw=0.8)\n        ax.scatter(h_pca[i, -1, 0], h_pca[i, -1, 1], color=\"#e74c3c\", s=20, zorder=5)\n    for i in [j for j in show_idx if y_true[j] == 0]:\n        ax.plot(h_pca[i, :, 0], h_pca[i, :, 1], color=\"#2ecc71\", alpha=0.3, lw=0.8)\n        ax.scatter(h_pca[i, -1, 0], h_pca[i, -1, 1], color=\"#2ecc71\", s=20, zorder=5)\n    ax.scatter([], [], color=\"#2ecc71\", s=20, label=\"LOS\")\n    ax.scatter([], [], color=\"#e74c3c\", s=20, label=\"NLOS\")\n    ax.legend(fontsize=9)\n    ax.set_title(f\"BERT+FP Hidden States (PCA on {h}-dim)\")\n    ax.set_xlabel(f\"PC1 ({100*pca.explained_variance_ratio_[0]:.1f}%)\")\n    ax.set_ylabel(f\"PC2 ({100*pca.explained_variance_ratio_[1]:.1f}%)\")\n    ax.grid(True, alpha=0.2)\n\n    ax = axs[1, 2]\n    ax.hist(y_prob[y_true == 0], bins=30, alpha=0.6, color=\"#27ae60\", label=\"LOS samples\", density=True)\n    ax.hist(y_prob[y_true == 1], bins=30, alpha=0.6, color=\"#e74c3c\", label=\"NLOS samples\", density=True)\n    ax.axvline(0.5, color=\"black\", ls=\"--\", lw=1.5, label=\"Threshold\")\n    ax.set_title(\"Prediction Distribution\"); ax.set_xlabel(\"P(NLOS)\"); ax.set_ylabel(\"Density\")\n    ax.legend(); ax.grid(True, alpha=0.3)\n\n    plt.suptitle(\"BERT+FP — Stage 1 Diagnostics (CIR + FP_AMPL prefix token)\",\n                 fontsize=16, fontweight=\"bold\", y=1.01)\n    plt.tight_layout()\n    plt.show()\n\n\nplot_diagnostics(best_model, best_data, best_history)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Transformer Hidden State Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_hidden_temporal(model, val_data, n_samples=5):\n    X_va, y_va, F_va = val_data\n    model.eval()\n    with torch.no_grad():\n        _, h_all = model(X_va, fp_features=F_va, return_dynamics=True)\n    y_true = y_va.cpu().numpy().flatten()\n    # Skip CLS (idx 0) + FP prefix token (idx 1) → CIR positions only\n    h_seq = h_all[:, 2:, :].cpu().numpy()\n    h_norm = np.linalg.norm(h_seq, axis=2)\n    x_input = X_va.cpu().numpy().squeeze(-1)\n    los_idx  = np.where(y_true == 0)[0][:n_samples]\n    nlos_idx = np.where(y_true == 1)[0][:n_samples]\n\n    fig, axs = plt.subplots(2, 2, figsize=(16, 10))\n    plt.subplots_adjust(hspace=0.4, wspace=0.3)\n    titles = [\n        (\"LOS signal\", los_idx, \"#2ecc71\", x_input),\n        (\"LOS ||h(t)|| (BERT+FP)\", los_idx, \"#27ae60\", h_norm),\n        (\"NLOS signal\", nlos_idx, \"#e74c3c\", x_input),\n        (\"NLOS ||h(t)|| (BERT+FP)\", nlos_idx, \"#c0392b\", h_norm),\n    ]\n    for ax, (title, idx, color, data) in zip(axs.flat, titles):\n        for i in idx:\n            ax.plot(data[i], alpha=0.55, color=color, lw=1.3)\n        ax.set_title(title, fontsize=10, fontweight=\"bold\")\n        ax.set_xlabel(\"Timestep\"); ax.grid(True, alpha=0.3)\n        ax.set_ylabel(\"Normalised CIR\" if \"signal\" in title else \"Hidden State Norm\")\n    plt.suptitle(\"BERT+FP Hidden State Temporal Profile — FP Prefix Token + Self-Attention\",\n                 fontsize=13, fontweight=\"bold\", y=1.01)\n    plt.tight_layout()\n    plt.show()\n\nplot_hidden_temporal(best_model, best_data, n_samples=5)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Test Set Evaluation & Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "best_model.eval()\nX_te = torch.tensor(X_test).to(device)\ny_te = torch.tensor(y_test).unsqueeze(1).to(device)\nF_te = torch.tensor(F_test).to(device)\n\nwith torch.no_grad():\n    test_pred = best_model(X_te, fp_features=F_te)\n    test_prob = test_pred.cpu().numpy().flatten()\n    test_acc  = ((test_pred > 0.5).float() == y_te).float().mean().item()\n    test_pred_np = (test_prob > 0.5).astype(float)\n    test_true_np = y_test.flatten()\n\nfpr, tpr, _ = roc_curve(test_true_np, test_prob)\ntest_auc = auc(fpr, tpr)\n\nprint(f\"Test Accuracy: {100*test_acc:.2f}%\")\nprint(f\"Test AUC:      {test_auc:.4f}\")\nprint(f\"\\nClassification Report:\")\nprint(classification_report(test_true_np, test_pred_np, target_names=[\"LOS\", \"NLOS\"]))\n\ncm = confusion_matrix(test_true_np, test_pred_np)\nfig, axs = plt.subplots(1, 2, figsize=(14, 5))\ndisp = ConfusionMatrixDisplay(cm, display_labels=[\"LOS\", \"NLOS\"])\ndisp.plot(ax=axs[0], cmap=\"Blues\", colorbar=False)\naxs[0].set_title(f\"BERT+FP — Test (Acc: {100*test_acc:.1f}%)\")\naxs[1].plot(fpr, tpr, color=\"#e74c3c\", lw=2, label=f\"AUC = {test_auc:.4f}\")\naxs[1].plot([0, 1], [0, 1], \"k--\", lw=1, alpha=0.5)\naxs[1].set_title(\"BERT+FP — Test ROC\"); axs[1].set_xlabel(\"FPR\"); axs[1].set_ylabel(\"TPR\")\naxs[1].legend(loc=\"lower right\"); axs[1].grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nModel: BERT_FP_Classifier (prefix token) | Embedding dim: {best_model.d_model} | Params: {sum(p.numel() for p in best_model.parameters()):,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: stage1_bert_fp_best.pt\n",
      "Saved: stage1_bert_fp_config.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(best_model.state_dict(), \"stage1_bert_fp_best.pt\")\n",
    "print(\"Saved: stage1_bert_fp_best.pt\")\n",
    "torch.save({\"config\": CONFIG}, \"stage1_bert_fp_config.pt\")\n",
    "print(\"Saved: stage1_bert_fp_config.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 BERT+FP complete.\n",
      "Compare with: BERT (CIR only), LNN+FP, LSTM+FP\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 1 BERT+FP complete.\")\n",
    "print(\"Compare with: BERT (CIR only), LNN+FP, LSTM+FP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}